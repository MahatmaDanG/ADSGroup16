{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define column names\n",
    "columns = ['year', 'month', 'day', 'hour', 'temperature', 'precipitation', 'u-wind', 'v-wind']\n",
    "\n",
    "# Load data from CSV without headers\n",
    "df = pd.read_csv(\"17.36N_78.5E.csv\", names=columns)\n",
    "df['temperature'] -= 273.15\n",
    "\n",
    "# Take a subset of the data for faster testing\n",
    "percentage = 0.4\n",
    "num_rows = len(df)\n",
    "top_rows = int(num_rows * percentage)\n",
    "df = df.head(top_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering\n",
    "df['datetime'] = pd.to_datetime(df[['year', 'month', 'day', 'hour']])\n",
    "df['season'] = df['datetime'].dt.month // 3 + 1\n",
    "df['time_of_day'] = pd.cut(df['hour'], bins=[-1, 6, 12, 18, 24], labels=[0, 1, 2, 3])\n",
    "df['day_of_week'] = df['datetime'].dt.day_of_week\n",
    "df['time_since_start'] = (df['datetime'] - df['datetime'].min()).dt.days\n",
    "df.drop(columns=['datetime'], inplace=True)\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.drop(columns=['temperature']),\n",
    "    df['temperature'],\n",
    "    test_size=0.2,\n",
    "    random_state=1\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 128 candidates, totalling 640 fits\n"
     ]
    }
   ],
   "source": [
    "# Define parameter grid for grid search\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(128,), (64, 32), (64, 64, 32), (128, 64, 32, 16)],\n",
    "    'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "    'solver': ['lbfgs', 'adam'],\n",
    "    'max_iter': [100, 200, 250, 300]\n",
    "}\n",
    "\n",
    "# Initialize MLPRegressor\n",
    "mlp = MLPRegressor()\n",
    "\n",
    "# Perform grid search\n",
    "grid_search = GridSearchCV(estimator=mlp, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Train the best model using the best parameters\n",
    "best_model = MLPRegressor(**best_params)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "test_loss = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Report test loss\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# Save the best model\n",
    "joblib.dump(best_model, 'ADS_Grid_Model.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ScikitLearn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
